server:
  host: localhost
  port: 7001
  reload: false
store:
  type: chroma
  collection_name: rag_documents
  persist_directory: ./chroma_db
  batch_size: 100
embedder:
  type: huggingface
  model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
  device: cpu
  batch_size: 32
chunker:
  default_strategy: adaptive
  strategies:
    adaptive:
      min_length: 100
      max_length: 500
      overlap: 50
      separators:
      - '


        '
      - '

        '
      - '. '
      - '! '
      - '? '
    fixed:
      chunk_size: 200
      overlap: 20
    semantic:
      min_chunk_size: 100
      max_chunk_size: 500
      overlap: 50
    sentence:
      sentences_per_chunk: 3
      overlap_sentences: 1
    markdown:
      max_chunk_size: 500
      respect_headers: true
llm:
  provider: gemini
  model: gemini-2.5-flash
  api_key: ${GEMINI_API_KEY}
  temperature: 0.01
  max_tokens: 8192
  timeout: 30
  available_models:
    gemini:
    - gemini-2.5-flash
    - gemini-2.5-pro
    - gemini-2.0-flash-exp
    - gemini-2.0-flash-thinking-exp
    - gemini-1.5-flash
    - gemini-1.5-flash-8b
    - gemini-1.5-pro
    - gemini-1.0-pro
    openai:
    - gpt-4o
    - gpt-4o-mini
    - gpt-4-turbo
    - gpt-4-turbo-preview
    - gpt-4
    - gpt-3.5-turbo
    - gpt-3.5-turbo-16k
    claude:
    - claude-3-5-sonnet
    - claude-3-opus
    - claude-3-sonnet
    - claude-3-haiku
    - claude-2.1
    - claude-2.0
reranker:
  type: bm25
  enabled: true
  k1: 1.2
  b: 0.75
retrieval:
  retrieve_k: 30
  rerank_k: 10
  max_context_chars: 12000
pipeline:
  query_expansion:
    enabled: false
    expansions: 0
ingester:
  max_parallel: 8
  batch_size: 100
cors:
  allow_origins:
  - http://localhost:*
  - http://127.0.0.1:*
  allow_credentials: true
  allow_methods:
  - '*'
  allow_headers:
  - '*'
logging:
  level: INFO
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  file: null
