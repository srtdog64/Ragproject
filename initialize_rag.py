#!/usr/bin/env python
"""
Initialize RAG system with sample data
Run this after starting the server for the first time
"""

import requests
import json
import time

def wait_for_server():
    """Wait for server to be ready"""
    print("Waiting for server to be ready...")
    for i in range(30):  # Wait up to 30 seconds
        try:
            response = requests.get("http://localhost:7001/health")
            if response.status_code == 200:
                print("‚úÖ Server is ready!")
                return True
        except:
            pass
        time.sleep(1)
        print(".", end="", flush=True)
    print("\n‚ùå Server did not start in time")
    return False

def initialize_chunker():
    """Initialize chunker with adaptive strategy"""
    try:
        # Set strategy to adaptive
        response = requests.post(
            "http://localhost:7001/api/chunkers/strategy",
            json={"strategy": "adaptive"},
            headers={"Content-Type": "application/json"}
        )
        if response.status_code == 200:
            print("‚úÖ Chunker strategy set to 'adaptive'")
        else:
            print(f"‚ö†Ô∏è  Chunker strategy setting returned {response.status_code}")
    except Exception as e:
        print(f"‚ùå Failed to set chunker strategy: {e}")

def load_initial_documents():
    """Load initial sample documents"""
    sample_docs = [
        {
            "id": "init-001",
            "title": "RAG ÏãúÏä§ÌÖú ÏÜåÍ∞ú",
            "source": "initialization",
            "text": """
            RAG(Retrieval-Augmented Generation)Îäî Ï†ïÎ≥¥ Í≤ÄÏÉâÍ≥º ÌÖçÏä§Ìä∏ ÏÉùÏÑ±ÏùÑ Í≤∞Ìï©Ìïú 
            ÌòÅÏã†Ï†ÅÏù∏ AI Í∏∞Ïà†ÏûÖÎãàÎã§. Ïù¥ ÏãúÏä§ÌÖúÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Ï£ºÏöî Íµ¨ÏÑ± ÏöîÏÜåÎ°ú Ïù¥Î£®Ïñ¥Ï†∏ ÏûàÏäµÎãàÎã§:
            
            1. Î¨∏ÏÑú ÏàòÏßë Î∞è Ï≤òÎ¶¨ (Document Ingestion)
            Î¨∏ÏÑúÎ•º ÏãúÏä§ÌÖúÏóê ÏûÖÎ†•ÌïòÍ≥† Ï†ÅÏ†àÌïú ÌÅ¨Í∏∞Î°ú Î∂ÑÌï†Ìï©ÎãàÎã§. Ïù¥ Í≥ºÏ†ïÏóêÏÑú Ï≤≠ÌÇπ(chunking) 
            Ï†ÑÎûµÏù¥ Îß§Ïö∞ Ï§ëÏöîÌï©ÎãàÎã§. Î¨∏ÏÑúÏùò Ïú†ÌòïÍ≥º ÌäπÏÑ±Ïóê Îî∞Îùº Î¨∏Ïû• Îã®ÏúÑ, Îã®ÎùΩ Îã®ÏúÑ, 
            ÎòêÎäî Ïä¨ÎùºÏù¥Îî© ÏúàÎèÑÏö∞ Î∞©ÏãùÏùÑ ÏÑ†ÌÉùÌï† Ïàò ÏûàÏäµÎãàÎã§.
            
            2. ÏûÑÎ≤†Îî© ÏÉùÏÑ± (Embedding Generation)
            ÌÖçÏä§Ìä∏Î•º ÏàòÏπòÏ†Å Î≤°ÌÑ∞Î°ú Î≥ÄÌôòÌï©ÎãàÎã§. Sentence-BERTÏôÄ Í∞ôÏùÄ Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ 
            ÏùòÎØ∏Ï†Å Ïú†ÏÇ¨ÏÑ±ÏùÑ Í≥ÑÏÇ∞Ìï† Ïàò ÏûàÎäî Î∞ÄÏßë Î≤°ÌÑ∞Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
            
            3. Î≤°ÌÑ∞ Ï†ÄÏû•ÏÜå (Vector Store)
            ÏÉùÏÑ±Îêú ÏûÑÎ≤†Îî©ÏùÑ Ìö®Ïú®Ï†ÅÏúºÎ°ú Ï†ÄÏû•ÌïòÍ≥† Í≤ÄÏÉâÌï† Ïàò ÏûàÎäî Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏûÖÎãàÎã§.
            
            4. Í≤ÄÏÉâ Î∞è ÏÉùÏÑ± ÌååÏù¥ÌîÑÎùºÏù∏
            ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏ÏùÑ Î∞õÏïÑ Í¥ÄÎ†® Î¨∏ÏÑúÎ•º Í≤ÄÏÉâÌïòÍ≥†, Ïù¥Î•º Î∞îÌÉïÏúºÎ°ú ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
            """
        },
        {
            "id": "init-002",
            "title": "ÏûÑÎ≤†Îî© Î™®Îç∏Ïùò Ï§ëÏöîÏÑ±",
            "source": "initialization",
            "text": """
            ÏûÑÎ≤†Îî©ÏùÄ ÌÖçÏä§Ìä∏Ïùò ÏùòÎØ∏Î•º ÏàòÏπòÏ†ÅÏúºÎ°ú ÌëúÌòÑÌïòÎäî Î∞©Î≤ïÏûÖÎãàÎã§. RAG ÏãúÏä§ÌÖúÏóêÏÑú 
            ÏûÑÎ≤†Îî©Ïùò ÌíàÏßàÏùÄ Ï†ÑÏ≤¥ ÏãúÏä§ÌÖú ÏÑ±Îä•Ïóê ÏßÅÏ†ëÏ†ÅÏù∏ ÏòÅÌñ•ÏùÑ ÎØ∏Ïπ©ÎãàÎã§.
            
            Îã§Íµ≠Ïñ¥ ÏßÄÏõê:
            ÏµúÏã† ÏûÑÎ≤†Îî© Î™®Îç∏Îì§ÏùÄ Ïó¨Îü¨ Ïñ∏Ïñ¥Î•º ÎèôÏãúÏóê ÏßÄÏõêÌï©ÎãàÎã§. ÏòàÎ•º Îì§Ïñ¥, 
            paraphrase-multilingual-MiniLM-L12-v2 Î™®Îç∏ÏùÄ 100Í∞ú Ïù¥ÏÉÅÏùò Ïñ∏Ïñ¥Î•º 
            ÏßÄÏõêÌïòÎ©∞, ÌïúÍµ≠Ïñ¥ÏôÄ ÏòÅÏñ¥Î•º ÎèôÏùºÌïú Î≤°ÌÑ∞ Í≥µÍ∞ÑÏóê Îß§ÌïëÌï† Ïàò ÏûàÏäµÎãàÎã§.
            
            This allows the system to handle queries in different languages and 
            retrieve relevant information regardless of the language used in the 
            original documents. The embedding models capture semantic meaning 
            rather than just lexical similarity.
            
            ÏûÑÎ≤†Îî© Ï∞®Ïõê:
            ÏùºÎ∞òÏ†ÅÏúºÎ°ú 384Ï∞®ÏõêÏóêÏÑú 768Ï∞®ÏõêÏùò Î≤°ÌÑ∞Í∞Ä ÏÇ¨Ïö©Îê©ÎãàÎã§. Ï∞®ÏõêÏù¥ ÎÜíÏùÑÏàòÎ°ù 
            Îçî ÎßéÏùÄ Ï†ïÎ≥¥Î•º Îã¥ÏùÑ Ïàò ÏûàÏßÄÎßå, Ï†ÄÏû• Í≥µÍ∞ÑÍ≥º Í≥ÑÏÇ∞ ÎπÑÏö©ÎèÑ Ï¶ùÍ∞ÄÌï©ÎãàÎã§.
            """
        },
        {
            "id": "init-003",
            "title": "Ï≤≠ÌÇπ Ï†ÑÎûµÏùò ÏÑ†ÌÉù",
            "source": "initialization",
            "text": """
            Ìö®Í≥ºÏ†ÅÏù∏ Ï≤≠ÌÇπ(chunking)ÏùÄ RAG ÏãúÏä§ÌÖúÏùò ÏÑ±Îä•ÏùÑ ÌÅ¨Í≤å Ìñ•ÏÉÅÏãúÌÇµÎãàÎã§.
            
            Ï£ºÏöî Ï≤≠ÌÇπ Ï†ÑÎûµ:
            
            1. Sentence-based Chunking
            - Î¨∏Ïû• Îã®ÏúÑÎ°ú ÌÖçÏä§Ìä∏Î•º Î∂ÑÌï†
            - Q&A ÌòïÏãùÏù¥ÎÇò ÎåÄÌôîÌòï Ïª®ÌÖêÏ∏†Ïóê Ï†ÅÌï©
            - Í∞Å Ï≤≠ÌÅ¨Í∞Ä ÏôÑÏ†ÑÌïú ÏùòÎØ∏ Îã®ÏúÑÎ•º Ïú†ÏßÄ
            
            2. Paragraph-based Chunking
            - Îã®ÎùΩ Îã®ÏúÑÎ°ú Î∂ÑÌï†
            - Íµ¨Ï°∞ÌôîÎêú Î¨∏ÏÑúÎÇò Îß§Îâ¥ÏñºÏóê Ïù¥ÏÉÅÏ†Å
            - Ïª®ÌÖçÏä§Ìä∏Í∞Ä Ïûò Î≥¥Ï°¥Îê®
            
            3. Sliding Window Chunking
            - Í≥†Ï†ï ÌÅ¨Í∏∞Ïùò ÏúàÎèÑÏö∞Î•º Ïù¥ÎèôÌïòÎ©∞ Î∂ÑÌï†
            - Í∏¥ ÏÑúÏà†Ìòï ÌÖçÏä§Ìä∏ÎÇò ÏÜåÏÑ§Ïóê Ï†ÅÌï©
            - Ïò§Î≤ÑÎû©ÏùÑ ÌÜµÌï¥ Í≤ΩÍ≥Ñ Ï†ïÎ≥¥ ÏÜêÏã§ Î∞©ÏßÄ
            
            4. Adaptive Chunking
            - ÌÖçÏä§Ìä∏ ÌäπÏÑ±ÏùÑ Î∂ÑÏÑùÌïòÏó¨ ÏûêÎèôÏúºÎ°ú ÏµúÏ†Å Ï†ÑÎûµ ÏÑ†ÌÉù
            - Îã§ÏñëÌïú Ïú†ÌòïÏùò Î¨∏ÏÑúÎ•º Ï≤òÎ¶¨Ìï† Îïå Ïú†Ïö©
            - ÏãúÏä§ÌÖúÏù¥ Ïä§Ïä§Î°ú ÌåêÎã®ÌïòÏó¨ Ï†ÅÏö©
            
            ÏÑ†ÌÉù Í∏∞Ï§Ä:
            - Î¨∏ÏÑúÏùò Íµ¨Ï°∞ÏôÄ ÌòïÏãù
            - ÏòàÏÉÅ ÏßàÎ¨∏Ïùò Ïú†Ìòï
            - Í≤ÄÏÉâ Ï†ïÌôïÎèÑ vs Ï≤òÎ¶¨ ÏÜçÎèÑ Í∑†Ìòï
            """
        }
    ]
    
    try:
        response = requests.post(
            "http://localhost:7001/ingest",
            json={"documents": sample_docs},
            headers={"Content-Type": "application/json"}
        )
        
        if response.status_code == 200:
            data = response.json()
            print(f"‚úÖ Initial documents loaded successfully")
            print(f"   - Documents: {data.get('documentCount', 0)}")
            print(f"   - Chunks created: {data.get('ingestedChunks', 0)}")
            return True
        else:
            print(f"‚ùå Failed to load documents: {response.status_code}")
            print(f"   Error: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error loading documents: {e}")
        return False

def test_system():
    """Test the system with sample queries"""
    test_queries = [
        "RAG ÏãúÏä§ÌÖúÏù¥ÎûÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?",
        "What are embedding models?",
        "Ï≤≠ÌÇπ Ï†ÑÎûµÏóêÎäî Ïñ¥Îñ§ Í≤ÉÎì§Ïù¥ ÏûàÎÇòÏöî?",
        "How do I choose the right chunking strategy?"
    ]
    
    print("\n" + "="*60)
    print("Testing system with sample queries...")
    print("="*60)
    
    for query in test_queries:
        print(f"\nüìù Query: {query}")
        try:
            response = requests.post(
                "http://localhost:7001/ask",
                json={"question": query},
                headers={"Content-Type": "application/json"}
            )
            
            if response.status_code == 200:
                data = response.json()
                answer = data['answer'][:200]  # First 200 chars
                if len(data['answer']) > 200:
                    answer += "..."
                print(f"‚úÖ Answer: {answer}")
                print(f"   (Latency: {data['latencyMs']}ms)")
            else:
                print(f"‚ùå Failed: {response.status_code}")
                
        except Exception as e:
            print(f"‚ùå Error: {e}")

def main():
    print("="*60)
    print("RAG System Initialization")
    print("="*60)
    
    # Wait for server
    if not wait_for_server():
        print("\nPlease start the server first:")
        print("  python start_server.py")
        return
    
    print("\n1. Setting up chunker...")
    initialize_chunker()
    
    print("\n2. Loading initial documents...")
    if load_initial_documents():
        print("\n3. Testing system...")
        test_system()
    
    print("\n" + "="*60)
    print("‚úÖ Initialization complete!")
    print("The RAG system is now ready to use.")
    print("="*60)

if __name__ == "__main__":
    main()
